\chapter{Existing Caching Approaches}
\label{chapter:caching}

Since caching is a solution widely used in practice there already exists multiple caching approaches described in literature, articles on the internet and in open source code. In this chapter we will cover some of these existing approaches. The approaches will be analyzed and evaluated based on the criteria described in section~\ref{sec:evaluating_caching_techniques} and requirements from section~\ref{sec:requirements}. The chapter will end with an overview of the different approaches and a final conclusion on how to choose the right caching technique.

\section{Expiration-based Invalidation}
\label{subsec:expiration_based_invalidation}

In some cases it is acceptable to serve stale values in a certain time interval. In these cases, the simplest approach would be to use the expiration-based invalidation technique, which gives up consistency and makes freshness depend on the chosen expiration, but is then able to respond with the cached object immediately independently of how underlying data changes.

The expiration-based invalidation works by assigning a TTL (Time to Live) to the cached object. At some point the TTL expires after which the cached object is considered invalid. The responsibility of invalidating cached values with TTL is often placed on the cache database by piggybacking the TTL to the cached value when it is stored. The cache database will then invalidate and remove expired values. This is for example supported by the in-memory cache database technologies, Redis and Memcached.

The timeline model on figure~\ref{fig:timeline:expiration-based}, illustrates how there is a time interval between the underlying data has been updated and the object has expired in which a stale version of the cached object is served.

\begin{figure*}[ht!]
  \centering
  \includegraphics[width=1.0\linewidth]{figures/timeline/expiration-based.pdf}
  \caption{The lifecycle of the expiration-based invalidation technique}
  \label{fig:timeline:expiration-based}
\end{figure*}

% section expiration_based_invalidation end

\section{Key-based Invalidation}
\label{subsec:key_based_invalidation}

When the cached values are required to be consistent with the primary storage, we must ensure that when underlying data is updated, the depending cached values are updated accordingly. The key-based invalidation gives these guarantees by giving up immediate responses. This means that the key-based invalidation will not be suitable in cases where the computation time exceeds the user's attention span or in cases where the cached values are updated too frequently.

Key-based invalidation works by constructing the cache key from the underlying data such that the key changes in lock-step with the cached content~\cite{blog:key-based-invalidation}. This means there is no specific name identifying some cached content and the cached content for a given key never changes. This simplifies version management from the perspective of cache storage since there is no chance you read stale values if the key is assumed to be derived from the most recent version of underlying data.

The challenge of this method is to construct the key. To use this technique correctly (i.e. obtain the guarantees promised) the programmer must construct a key that is ensured to change when the cached value is considered stale. Furthermore to obtain a maximum hit rate, the key must not change when the cached value is fresh. Given that the key is optimally constructed, the timeline looks as on figure~\ref{fig:timeline:key-based}. A cached object is considered invalid in the moment after the cache key components are updated (e.g. the \emph{updated\_timestamp} in the code snippet). This means the freshness and validity interval always overlap in the timeline model, and we therefore have consistency.

\begin{figure*}[ht!]
  \centering
  \includegraphics[width=1.0\linewidth]{figures/timeline/key-based.pdf}
  \caption{The lifecycle of the key-based invalidation technique}
  \label{fig:timeline:key-based}
\end{figure*}

In the web application framework, Ruby on Rails, key-based invalidation is implemented by construction the key from the timestamp of the last time the underlying data was updated. The next time the underlying data is updated, the timestamp also changes, and the cached content have thereby been invalidated. An example of this technique can be seen in code snippet~\ref{code:key-based-invalidation}. In this code snippet we use the function name, entity type, entity id and update timestamp as parts of the key. This means that the cached value is invalidated when any of these values changes. The intuition behind these components is that we want a unique cached object for each entity and function and we want the value to be recomputed when the entity is updated i.e. the update timestamp changes.

\begin{code}{Example of the key-based invalidation technique}
  \input{code/key_based_invalidation.py}
  \label{code:key-based-invalidation}
\end{code}

A caveat of this method method is that it generates cache garbage since new version of cached objects does not overwrite the content for existing keys but stored with a new key. To avoid the complexity of keeping track of the relations between the different cached objects, the responsibility for cleaning up old cached objects is moved to the cache database. Fortunately cache databases (such as Redis and Memcached) implements different cleanup algorithms that detects obsolete values based on some policy. One such policy called \emph{Least Recently Used (LRU)} removes the objects that are least recently used. Another policy called \emph{Least Frequently Used (LFU)} removes the lease frequently accessed objects.

% section key_based_invalidation end

\section{Trigger-based Invalidation}
\label{subsec:trigger_based_invalidation}

Instead of invalidating the cached object when requested, the cached values can be invalidated based on certain events triggered when the underlying data is updated. Given that the invalidation triggers are located at all the places where the underlying data is updated, we can achieve the same guarantees of consistency and freshness as with key-based invalidation. As seen on figure~\ref{fig:timeline:trigger-based}, the timeline is similar to the key-based invalidation and thereby gives the same guarantees of freshness and consistency.

\begin{figure*}[ht!]
  \centering
  \includegraphics[width=1.0\linewidth]{figures/timeline/trigger-based.pdf}
  \caption{The lifecycle of the trigger-based invalidation technique}
  \label{fig:timeline:trigger-based}
\end{figure*}

In key-based invalidation the key is dynamic and used as an invalidation mechanism, but in trigger-based invalidation the key is static i.e. it does not change in the lifetime of a cached object. We will therefore call it the \emph{name} of the cached object. The actual key becomes simpler since it is only responsible for uniquely identifying the cached value, but the localization is still a challenge since the key needs to be shared between the triggers and the places where the cached objects are accessed.

Having a static key also has the advantage that we can locate the old/stale value after invalidation as oppose to key-based invalidation where there is no relation between the versions of cached values. Using this information we can extend the technique to be more fault-tolerant by serving a stale value in the case where a computation fails\footnote{Here we assume that the application provides more value to the client by serving a stale value compared to serving an error or nothing}. Trigger-based invalidation is also a technique that comes with a lot of flexibility and is easy to extend as done in section~\ref{subsec:trigger-based-invalidation-with-asynchronous-update} and section~\ref{subsec:write_through_invalidation}.

The simplest type of triggers are manually defined code that invalidates a given key. A code snippet for a naive implementation of manual triggers can be seen in code snippet~\ref{code:manual-trigger-invalidation}. In practice the manual code triggers are often placed right after updates to the underlying data. Although this method is simple it often requires a lot of effort from the programmer and is prone to errors since it requires global reasoning of the application to identify the places where underlying data is updated.

\begin{code}{Example of how trigger based invalidation works with manual code invalidation}
  \input{code/manual_trigger_invalidation.py}
  \label{code:manual-trigger-invalidation}
\end{code}

Having a static key also introduces a challenge related to concurrency since we assume that there are multiple application servers. The challenge origins from the problem illustrated on figure~\ref{fig:trigger-based-concurrency-problem}, where an update to the underlying happens during the computation of a cached value. When the computation has finished it will incorrectly mark the cached value as fresh even though it is based on an old version of the underlying data.

\begin{figure*}[ht!]
  \centering
  \includegraphics[width=1.0\linewidth]{figures/trigger-based-concurrency-problem.pdf}
  \caption{A scenario of the trigger-based invalidation that results in a race condition, where the cached value are being incorrectly marked as valid even though it is storing a stale value.}
  \label{fig:trigger-based-concurrency-problem}
\end{figure*}

% section trigger_based_invalidation end

\section{Trigger-based Invalidation with Asynchronous Update}
\label{subsec:trigger-based-invalidation-with-asynchronous-update}

We can extend the trigger-based invalidation by always serving the newest value from the cache and afterwards update the value asynchronously if it is stale. This way we always get an immediate response by giving up strict freshness and consistency.

The timeline of this extension is as on figure~\ref{fig:timeline:trigger-based-with-asynchronous-update}. A naive implementation of this technique would be as the trigger-based seen in code snippet~\ref{code:manual-trigger-invalidation} with the modification that the system updates the value asynchronously instead of synchronously if no fresh value is found in the cache. An implementation example for this technique can be found in appendix~\ref{appendix:code:trigger-based-invalidation-with-asynchronous-update}.

\begin{figure*}[ht!]
  \centering
  \includegraphics[width=1.0\linewidth]{figures/timeline/trigger-based-with-asynchronous-update.pdf}
  \caption{The lifecycle of the \emph{trigger-based invalidation} technique where the value is updated in the asynchronous}
  \label{fig:timeline:trigger-based-with-asynchronous-update}
\end{figure*}

% section trigger-based-invalidation-with-asynchronous-update end

\section{Write-Through Invalidation}
\label{subsec:write_through_invalidation}

Write-through invalidation is also an extension to the trigger-based invalidation approach, but instead of updating the cached values when the value is requested, the value is updated in the moment after it has been invalidated. This way we invalidate by writing through the existing version in the cache. The timeline model of this technique seen on figure~\ref{fig:timeline:write-through} is similar to the asynchronous update extension, but the time interval in which it serves a stale value is only as long as the time taken to compute the value.

\begin{figure*}[ht!]
  \centering
  \includegraphics[width=1.0\linewidth]{figures/timeline/write-through.pdf}
  \caption{The lifecycle of the \emph{write-through invalidation} technique}
  \label{fig:timeline:write-through}
\end{figure*}

% section write_through_invalidation end

\section{Automatic Invalidation}
\label{subsec:automatic_invalidation}

The trigger-based invalidation is an attractive technique since it can provide guarantees with relation to freshness and consistency while allowing for flexibility by extending it. But in practice the overhead for the programmer of managing the triggers and keeping integrity becomes a burden that makes it hard to maintain. A lot of research have therefore been done in making it easier to use trigger-based invalidation by automating cache invalidation and management.

The cached objects are based on underlying data from the primary storage system, which means that changes to the underlying data also origins from the primary store. A lot of work have been put into using the database as the source of the triggers that invalidates the cached objects.

Cache-Genie~\cite{paper:cache-genie} caches complex database queries by letting the programmer declare predefined queries, which are then cached and updated automatically. It uses an Object-Relational Mapper to detect and trigger changes to underlying data, which will invalidate and update the affected cached queries.

The deploy-time model suggested in~\cite{paper:deploy-time} also uses the database wrapper to trigger changes to underlying data, but instead of just caching database queries, the deploy-time model is able to cache the results of functions. The programmer is able to declare a function as cached in the source code with declaration of dependencies to underlying data after which the cache system will invalidate the cached functions automatically. The deploy-time model uses static analysis to detect dependencies between different cached functions and to underlying data.

TxCache suggested by Dan Ports et.al.~\cite{paper:liskov} also caches the results of functions, but it uses a fully transparent programming model that allows a programmer to declare a function to be cached without any additional information. The TxCache patches the primary storage system to support ``invalidation streams'' and transactions to detect queries made during a call to a cached function. The primary storage distributes the ``invalidation stream'' to the cache databases, which uses the stream to invalidate affected cached objects. Using this approach, it is possible to achieve transactional consistency across the cache and primary storage without enforcing full freshness by serving slightly stale data. That is, the TxCache improves the performance of requests to the users while ensuring that all the data served to the user is consistent for the given request. This technique is able to give a very strong guarantee, but it also comes with complexity in the architecture, since it requires an external process that manages snapshots of the databases and it requires the primary storage database to support the invalidation stream technique.

On the other end of the granularity scale,~\cite{paper:db-driven-http} suggests a system that caches HTTP responses. It uses a proxy that that detects the queries made to the primary storage during a HTTP request. Through the information captured by the proxy, the system builds a table that maps a given HTTP resource to the queries made. Furthermore it uses a proxy between the application and database to detect changes to underlying data and invalidate affected cached HTTP responses. This method is interesting since it allows to cache without changing the code of the web application, but it is only described at the granularity of HTTP responses since it uses the communication between the web application, storage system and cache to achieve automatic invalidation. A similar approach is suggested in~\cite{paper:db-driven2}.

In a series of papers, IBM describes the Content Management System (CMS) they developed for the Olympic Games in 2000~\cite{paper:ibm, paper:ibm-extended, paper:ibm-publishing-system}. In these paper they introduce the Object Dependence Graph (ODG) data structure (described in more details in section~\ref{sec:simple-object-dependence-graph}) that is optimized for querying the content affected by changes to underlying data. In this system the dependencies between the different content and the underlying data are declared by the content-writers. That is, the dependencies are not declared in the code base, but they are declared directly in the data. Experiments made to the final system achieves a 100\% cache hit rate and the papers describes interesting ideas with relation to automatic invalidation, but the final system is designed to be used for a CMS-systems.

To be able to evaluate the techniques used in the automatic invalidation approaches described, we will divide the process into different sub problems. Automatic invalidation are based on a caching system that reacts and invalidates when changes happens to underlying data. Automatic invalidation are therefore mainly working around requests, where the client updates underlying data in the primary store. If we consider figure~\ref{fig:automatic-invalidation-flow} that illustrates this flow, the invalidation mechanism is responsible for step 3, 4 and 5. This involves the tasks of: \emph{triggering cache invalidation} and \emph{managing dependencies between underlying data and cached objects}. The following sections will consider these tasks and compare existing techniques.

\begin{figure*}[ht!]
  \centering
  \includegraphics[width=0.9\linewidth]{figures/automatic-invalidation-flow.png}
  \caption{The control flow of automatic invalidation when a client requests to update underlying data}
  \label{fig:automatic-invalidation-flow}
\end{figure*}

\subsection{Triggering Cache Invalidation}
\label{subsubsec:triggering-cache-invalidation}

% Cache-Genie:
By using the database wrapper as in~\cite{paper:cache-genie, paper:deploy-time}, the application becomes responsible for detecting changes to underlying data such that the cache system does not need to introduce external processes listening to changes or patch the database. One advantage of using a database wrapper is that in some cases, the wrapper is able to support multiple database technologies such that it e.g. is possible to switch from one SQL technology to another without changing much code. On the other hand changes made to the database that are not made through the given database wrapper are not detected as a trigger, which leaves the responsibility of ensuring all changes are made through the database wrapper. By using a database wrapper we therefore get better adaptability by simplifying the architecture, but require discipline with relation to how changes are made to the primary storage.

Other solutions such as~\cite{paper:liskov, paper:ibm, paper:ibm-extended} assumes that the database is able to send notifications when changes are made to the database. The information from the notifications are intercepted by the caching system and converted to invalidations.~\cite{paper:liskov} uses an ``invalidation stream'' that is replicated directly across all cache nodes, which means the cache nodes has the responsibility of invalidating the correct cached objects. In~\cite{paper:ibm, paper:ibm-extended} this responsibility is extracted into a \emph{cache manager} that transforms the change notifications to invalidations. A similar approach is used in~\cite{paper:db-driven-http} uses a proxy between the application and the primary storage to ``sniff'' the database traffic and relate it to the HTTP-request of the client.

A comparison of different invalidation trigger techniques is shown on figure~\ref{fig:invalidation-trigger-comparison}.

\begin{table}[ht!]
  \footnotesize
  \centering
  \begin{tabular}{lll}
    \hline
    & \textbf{Advantages} & \textbf{Disadvantages} \\
    \hline
    {
      \emph{Directly from Database}
    } & {
      \parbox{3.5cm}{
        \begin{itemize}[leftmargin=0.75em]
          \item Any change is captured
        \end{itemize}
      }
    } & {
      \parbox{3.5cm}{
        \begin{itemize}[leftmargin=0.75em]
          \item Require database to support triggers
        \end{itemize}
      }
    } \\
    \hline
    {
      \emph{Database Sniffer}
    } & {
      \parbox{3.5cm}{
        \begin{itemize}[leftmargin=0.75em]
          \item Any change is captured
        \end{itemize}
      }
    } & {
      \parbox{3.5cm}{
        \begin{itemize}[leftmargin=0.75em]
          \item Require a database sniffer for the database technology used
          \item Requires an extra running process
        \end{itemize}
      }
    } \\
    \hline
    {
      \emph{Database Wrapper}
    } & {
      \parbox{3.5cm}{
        \begin{itemize}[leftmargin=0.75em]
          \item Supports all database technologies supported by the database wrapper or the API used by the database wrapper
        \end{itemize}
      }
    } & {
      \parbox{3.5cm}{
        \begin{itemize}[leftmargin=0.75em]
          \item Changes made to the database around the database wrapper are not detected
        \end{itemize}
      }
    } \\
    \hline
  \end{tabular}
  \caption{Comparison of triggers for automatic invalidation}
  \label{fig:invalidation-trigger-comparison}
\end{table}

% subsection triggering-cache-invalidation end

\subsection{Dependency Management}
\label{subsubsec:dependency-management}

After the invalidation has been triggered, the invalidation system needs to locate the cache objects that must be invalidated. This involves the task of identifying and declaring dependencies such that the triggers will invalidate the affected cached objects efficiently.

Since dependency management is a burden for the programmer and affects the correctness of the cache implementation, it would be most desirable to have fully automatic dependency management, which is achieved in~\cite{paper:liskov, paper:db-driven-http}.~\cite{paper:db-driven-http} use the technique of proxies between the different servers to sniff the traffic and thereby automatically derive dependencies between HTTP-responses and queries made during the request.~\cite{paper:liskov} runs a transaction with the database while the cached object is computed and uses information from the queries made during the transactions to derive dependencies between the underlying data and the cached object. These techniques removes the burden of cache management by having fully transparent caching, but it also means the programmer has less flexibility. Furthermore they are tightly coupled to the technologies used and makes it difficult to port the solutions to other technologies.

Other solutions such as~\cite{paper:cache-genie, paper:deploy-time} relies on the programmer declaring dependencies from the cached objects to underlying data. Since the trigger can include information about which underlying data are changed, the caching system can use the declared dependencies to invalidate the corresponding cached objects.~\cite{paper:cache-genie} supports declarations through function calls that are stored in the memory of the application. The deploy-time model suggested in~\cite{paper:deploy-time} uses static analysis of comments to allow the functions to be executed without the cache database. These techniques does not remove the burden of cache management completely, but they allow the programmer to specify the dependencies in a more declarative and robust way compared to using manual invalidation triggers.

The solution suggested by Jim Challenger et.al.~\cite{paper:ibm, paper:ibm-extended} uses dependencies declared in the content to construct an advanced dependency graph. When updates are made to content or underlying data, the affected cached objects are derived using the dependency graph. This solution is developed for a content management system, where the users can declare dependencies between the fragments of the content i.e. the dependencies are declared in each entity. This makes it unfeasible to use in application with slightly advanced data models, but it solves the problem well in the given case.

An overview of this discussion can be found in figure~\ref{fig:dependency-management-comparison}.

\begin{table}[ht!]
  \footnotesize
  \centering
  \begin{tabular}{lll}
    \hline
    & \textbf{Advantages} & \textbf{Disadvantages} \\
    \hline
    {
      \parbox{3.5cm}{
        \emph{Declared in code} \\ (\cite{paper:cache-genie})
      }
    } & {
      \parbox{3.5cm}{
        \begin{itemize}[leftmargin=0.75em]
          \item Easy to reason about dependencies
        \end{itemize}
      }
    } & {
      \parbox{3.5cm}{
        \begin{itemize}[leftmargin=0.75em]
          \item Relies on the developer declaring dependencies
        \end{itemize}
      }
    } \\
    \hline
    {
      \parbox{3.5cm}{
        \emph{Declared in content} \\ (\cite{paper:ibm, paper:ibm-extended})
      }
    } & {
      \parbox{3.5cm}{
        \begin{itemize}[leftmargin=0.75em]
          \item Allow different data source for different entities
          \item The developer does not have to declare dependencies
        \end{itemize}
      }
    } & {
      \parbox{3.5cm}{
        \begin{itemize}[leftmargin=0.75em]
          \item Burden for users to define dependencies on each entity
        \end{itemize}
      }
    } \\
    \hline
    {
      \parbox{3.5cm}{
        \emph{Code Generation From Static Analysis} \\ (\cite{paper:deploy-time})
      }
    } & {
      \parbox{3.5cm}{
        \begin{itemize}[leftmargin=0.75em]
          \item Semi transparent  (requires definition of database relations)
        \end{itemize}
      }
    } & {
      \parbox{3.5cm}{
        \begin{itemize}[leftmargin=0.75em]
          \item Does not work for dynamic programming languages
          \item Difficult to detect relational dependencies
          \item Requires knowledge about static analysis to implement
        \end{itemize}
      }
    } \\
    \hline
    {
      \parbox{3.5cm}{
        \emph{Database Transactions with Invalidation Tags} \\ (\cite{paper:liskov})
      }
    } & {
      \parbox{3.5cm}{
        \begin{itemize}[leftmargin=0.75em]
          \item Fully transparent
        \end{itemize}
      }
    } & {
      \parbox{3.5cm}{
        \begin{itemize}[leftmargin=0.75em]
          \item Require the database to implement the transactions
        \end{itemize}
      }
    } \\
    \hline
  \end{tabular}
  \caption{Comparison of dependency management techniques for automatic invalidation}
  \label{fig:dependency-management-comparison}
\end{table}

% subsection dependency-management end

% section caching_approaches_in_web_development end

\section{Choosing the Right Caching Technique}
\label{sec:choosing_the_right_caching_technique}

In general there is not a best or correct caching solution - it's a matter of choosing the solution best suited in the given context depending on the architecture of the web application and the specific use case. To get closer to the solution suited for our context (section~\ref{sec:context}) we will compare the existing approaches based on the criteria described in section~\ref{sec:evaluating_caching_techniques}. An overview of the comparison on table~\ref{fig:existing-solutions-comparison} shows how the different caching approaches relates to the evaluation criteria.

\begin{table}[htpb]
  \scriptsize
  \doublespacing
  \hspace*{-1cm}
  \begin{tabular}{lcccccc}
{} & {
  \textbf{Consistency}
} & {
  \twolinecell{1.2cm}{Strict}{Freshness}
} & {
  \threelinecell{1.2cm}{Update}{On}{Invalidation}
} & {
  \threelinecell{1.4cm}{Always}{Immediate}{Response}
} & {
  \twolinecell{1.4cm}{No Cache}{Management}
} & {
  \textbf{Adaptability}
} \\
  \hline
  \textbf{Arbitrary Content}           & & & & & & \\
  Expiration-based                     & \no  & \no  & \no  & \yes & \yes & \high \\[7pt]
  Key-based                            & \yes & \yes & \no  & \no  & \no  & \high \\[7pt]
  Manual Trigger-based                 & \yes & \yes & \no  & \no  & \no  & \high \\[7pt]
  Async. Update                        & \no  & \no  & \no  & \yes & \no  & \high \\[7pt]
  Write-Trough                         & \no  & \no  & \yes & \yes & \no  & \med  \\[7pt]
  Chris Wasik~\cite{paper:deploy-time} & \yes & \yes & \no  & \yes & \opt\sss{*} & \med  \\[7pt]
  TxCache~\cite{paper:liskov}          & \yes & \opt\sss{**}  & \no  & \opt\sss{**} & \yes & \low \\[7pt]
  \hline
  \textbf{Declared Content}            & & & & & & \\
  IBM~\cite{paper:ibm, paper:ibm-extended} & \no & \no & \yes & \yes & \yes & \low \\[7pt]
  \hline
  \textbf{HTTP-Response}               & & & & & & \\
  Chang et.al.~\cite{paper:db-driven-http} & \no & \no & \yes & \yes & \yes & \low \\[7pt]
  \hline
  \textbf{DB-Queries}                   & & & & & & \\
  Cache-Genie~\cite{paper:cache-genie}  & \yes & \no & \yes & \yes & \yes & \med \\[7pt]
  Materialized Views                    & \no & \no & \no  & \yes & \yes & \med \\[7pt]
  \hline
  \multicolumn{7}{l}{*) Dependencies to underlying data must be declared, **) Does not give these guarantees fully, but approximately.}
  \end{tabular}
  \caption{Comparison of caching approaches for different types of content}
  \label{fig:existing-solutions-comparison}
\end{table}

% section choosing_the_right_caching_technique end
