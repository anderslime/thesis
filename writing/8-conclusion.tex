\chapter{Conclusion}
\label{chapter:conclusion}

Caching is a popular technique for improving the performance and scalability of web applications, but it also relies on the programmer correctly managing the cache and making decisions about the freshness and cache updates. In some cases the cached computations are taking a long time to compute and a cache miss resulting in a user waiting for the computation would be fatal for the user experience.

In this thesis we have analyzed the challenges of cache management and presented a set of evaluation criteria to find the appropriate caching technique for a given use case. The evaluation criteria was applied to existing caching solutions used in practical web development and described in research. From the existing solutions we found no technique that solved the problem while meeting the requirements, and the thesis therefore introduces a new application-level caching system, Smache. Smache presents a programming model that allows the programmer to mark existing functions as cached by declaring the dependencies to underlying data used to compute the function. The cached functions are automatically invalidated and updated when the underlying data changes. Smache uses timestamp invalidation to ensure the integrity of the cached values and represents the dependencies using a variant of the Object Dependence Graph data structure to find affected cached values efficiently. Smache was implemented in Python and integrated into the Peergrade.io-platform.

Smache makes it easier for the programmer to cache long running computations without affecting the user experience of the end user. It has been designed to be easy to integrate into existing applications with a possibility to cache existing functions without changing the code inside the function and by reusing architectural components used in many web application. Our experiments performed on the Smache library showed that it only introduces a constant overhead for existing operations of the application and the update throughput showed to increase when more updates where processed concurrently. That is, Smache can be scaled horizontally by adding more update workers to maintain the update throughput when the number of users rises or when new cached functions are introduces.

To our knowledge, Smache is the first caching system with automatic invalidation and in-place updates that allows to cache arbitrary computations.

\section{Future Work}
\label{sec:future_work}

Smache provides a foundation for a flexible and efficient caching library, which can lead to extensions and improvements. The improvements can also result in final contributions to the Smache library by contributing to the open-source version at:

\url{https://github.com/anderslime/smache}

The following list are our ideas for future projects as extension of this thesis:

\begin{itemize}
  \item \textbf{Transparent Dependency Registration}: The version of Smache described in this thesis relies on the developer identifying the underlying data used for a given computation. Even though it becomes simpler than the traditional invalidation techniques, it would be even easier to cache functions if this task was performed automatically by Smache as in the solution suggested by Dan Ports~\cite{paper:liskov}.
  \item \textbf{Fault-Tolerant Improvements}: As a trade-off for simplicity, this thesis did not design Smache to be fully fault-tolerant, which means the tolerance of faults are limited in areas of the solution as discussed in section~\ref{sec:discussion-on-fault-tolerance}. In the same section we also suggest improvements to make the solution more fault-tolerant to e.g. handle failures happening to the queue and failures of the cache database.
  \item \textbf{Hybrid Invalidation}: The focus of this thesis was to cache in the use case with long running computations. Since Smache provides a strong foundation for invalidation and update scheduling, it would be beneficial to extend Smache with other invalidation approaches such as expiration-based invalidation. This could allow for interesting optimizations such as declare only declare a subset of the dependencies to the underlying data but also update the value every week.
  \item \textbf{Scheduling Optimizations}: Smache uses concurrency to achieve a simple scheduling solution while achieving a high throughput as a trade-off for efficiency. While simplicity is a desirable property, it could be necessary to optimize the scheduling in applications of larger scale.
  \item \textbf{Test on Massive Scale}: Smache was designed for the common web application, which is not considered a large scale compared to e.g. Facebook architectures. It would be interesting to research what is required to use Smache on larger scale.
  \item \textbf{Other Primary Storage Technologies}: Smache has been implemented to support MongoDB, because it is used by Peergrade.io, but i has been implemented as an adapter. To make Smache adaptable for more web applications and to test the flexibility of the Smache design, it would therefore be interesting to add adapters for other database technologies such as PostgreSQL and MySQL.
  \item \textbf{Other Programming Languages}: Smache is implemented in Python, also used by Peergrade.io, but to test the flexibility of the design, it would be interesting to implement Smache in other programming languages such as Ruby, Java and C\#.
\end{itemize}

% section future_work end


% chapter conclusion end

